{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style-transfer-skeleton.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w-rMk6eXogBG",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ue2qVsk0o8P1"
      },
      "source": [
        "## Style Transfer - DIY with PyTorch and Google Colab\n",
        "\n",
        "Created for TMCS software development course, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2uMszD-75Ig",
        "colab_type": "text"
      },
      "source": [
        "To perform a style transfer is to take any arbitrary image and process it such that it takes on the stylistic features of another image fed in to the algorithm. The procedure for doing this is described in *A Neural Algorithm of Artistic Style*, paper of L.A. Gatys, A.S. Ecker, and M. Bethge - linked\n",
        "[here](https://https://arxiv.org/pdf/1508.06576.pdf) .\n",
        "\n",
        "My reason for choosing to use a Google Colab notebook for this project is that we will be operating on large tensor objects. Operating on tensors is highly parallelisable and Google provides GPUs that you all can use for free via a browser, without having to deal with CUDA, which will hopefully speed up the development process.\n",
        "\n",
        "This notebook will provide a framework that you will use to write your own modules that, once they pass the tests given below, will come together on Friday  - BYOP (bring your own pictures)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoyFLv3rOw6z",
        "colab_type": "text"
      },
      "source": [
        "The algorithm is simple - it takes a style image, a content image, and an input (seed) image and uses a pre-trained VGG neural net to output a style transfered image. We define two distances - content and style - that measure how far the input image is from the other two, then use gradient descent to minimise both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGj6W9-z82jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}